{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from notebooks/data_loader.ipynb\n",
      "importing Jupyter notebook from notebooks/helper_fxns.ipynb\n",
      "importing Jupyter notebook from notebooks/print_n_plot.ipynb\n",
      "importing Jupyter notebook from notebooks/build_network.ipynb\n",
      "importing Jupyter notebook from notebooks/train_val.ipynb\n",
      "importing Jupyter notebook from notebooks/objectives.ipynb\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import argparse\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from notebooks.data_loader import *\n",
    "from notebooks.helper_fxns import *\n",
    "from notebooks.print_n_plot import *\n",
    "from notebooks.build_network import *\n",
    "from notebooks.train_val import *\n",
    "import warnings\n",
    "import lasagne\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import sys\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import argparse\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_kwargs():\n",
    "    \n",
    "    default_args = {'input_shape': tuple([None] + [1, 50, 50]), \n",
    "                      'learning_rate': 0.01, \n",
    "                      'dropout_p': 0, \n",
    "                      'weight_decay': 0, #0.0001, \n",
    "                      'num_filters': 64, \n",
    "                      'num_fc_units': 32,\n",
    "                      'num_layers': 4,\n",
    "                      'momentum': 0.9,\n",
    "                      'num_epochs': 10000,\n",
    "                      'batch_size': 128,\n",
    "                     \"save_path\": \"None\",\n",
    "                    \"num_events\": 1000,\n",
    "                    \"sig_eff_at\": 0.9996}\n",
    "    \n",
    "    \n",
    "    # if inside a notebook, then get rid of weird notebook arguments, so that arg parsing still works\n",
    "    if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "        sys.argv=sys.argv[:1]\n",
    "\n",
    "\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    #make a command line argument for every flag in default args\n",
    "    for k,v in default_args.iteritems():\n",
    "        parser.add_argument('--' + k, type=type(v), default=v, help=k)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if args.save_path == \"None\":\n",
    "        save_path = None\n",
    "    else:\n",
    "        save_path = args.save_path\n",
    "\n",
    "\n",
    "    kwargs = default_args\n",
    "    kwargs.update(args.__dict__)\n",
    "    run_dir = create_run_dir(save_path)\n",
    "    kwargs['save_path'] = run_dir\n",
    "    kwargs[\"logger\"] = get_logger(kwargs['save_path'])\n",
    "    \n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'num_layers': 4, 'input_shape': (None, 1, 50, 50), 'batch_size': 128, 'dropout_p': 0, 'num_events': 1000, 'num_epochs': 10000, 'weight_decay': 0, 'sig_eff_at': 0.9996, 'num_fc_units': 32, 'save_path': './results/run207', 'num_filters': 64, 'logger': <logging.Logger object at 0x7fe441f32a50>, 'momentum': 0.9}\n",
      "<lasagne.layers.input.InputLayer object at 0x7fe42c410a10>(None, 1, 50, 50)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7fe42c3d4b90>(None, 64, 50, 50)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7fe42c3c7f50>(None, 64, 50, 50)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7fe42c3e9ad0>(None, 64, 50, 50)\n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x7fe42c3e9c10>(None, 64, 25, 25)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7fe42c3e9c50>(None, 64, 25, 25)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7fe42c3e9e50>(None, 64, 25, 25)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7fe42c3c5250>(None, 64, 25, 25)\n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x7fe42c3c5390>(None, 64, 12, 12)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7fe42c3c53d0>(None, 64, 12, 12)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7fe42c3c55d0>(None, 64, 12, 12)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7fe42c3c5990>(None, 64, 12, 12)\n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x7fe42c3c5ad0>(None, 64, 6, 6)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7fe42c3c5b10>(None, 64, 6, 6)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7fe42c3c5d10>(None, 64, 6, 6)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7fe42c375110>(None, 64, 6, 6)\n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x7fe42c375250>(None, 64, 3, 3)\n",
      "<lasagne.layers.noise.DropoutLayer object at 0x7fe42c3d4b50>(None, 64, 3, 3)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x7fe42c3752d0>(None, 32)\n",
      "<lasagne.layers.noise.DropoutLayer object at 0x7fe42c375790>(None, 32)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x7fe42c375950>(None, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<lasagne.layers.input.InputLayer object at 0x7fe42c410a10> : (None, 1, 50, 50)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7fe42c3d4b90> : (None, 64, 50, 50)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7fe42c3c7f50> : (None, 64, 50, 50)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7fe42c3e9ad0> : (None, 64, 50, 50)\n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x7fe42c3e9c10> : (None, 64, 25, 25)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7fe42c3e9c50> : (None, 64, 25, 25)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7fe42c3e9e50> : (None, 64, 25, 25)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7fe42c3c5250> : (None, 64, 25, 25)\n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x7fe42c3c5390> : (None, 64, 12, 12)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7fe42c3c53d0> : (None, 64, 12, 12)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7fe42c3c55d0> : (None, 64, 12, 12)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7fe42c3c5990> : (None, 64, 12, 12)\n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x7fe42c3c5ad0> : (None, 64, 6, 6)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7fe42c3c5b10> : (None, 64, 6, 6)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7fe42c3c5d10> : (None, 64, 6, 6)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7fe42c375110> : (None, 64, 6, 6)\n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x7fe42c375250> : (None, 64, 3, 3)\n",
      "<lasagne.layers.noise.DropoutLayer object at 0x7fe42c3d4b50> : (None, 64, 3, 3)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x7fe42c3752d0> : (None, 32)\n",
      "<lasagne.layers.noise.DropoutLayer object at 0x7fe42c375790> : (None, 32)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x7fe42c375950> : (None, 2)\n",
      "130722\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning epoch 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    kwargs = setup_kwargs()\n",
    "    \n",
    "    h5_prefix = \"/project/projectdirs/dasrepo/atlas_rpv_susy/hdf5/prod003_2016_11_14\"\n",
    "    \n",
    "    dl = DataLoader(bg_cfg_file=[join(h5_prefix, \"jetjet_JZ4.h5\"),\n",
    "                                 join(h5_prefix, \"jetjet_JZ5.h5\")],\n",
    "                    sig_cfg_file=join(h5_prefix, \"GG_RPV10_1400_850.h5\"),\n",
    "                    num_events=kwargs[\"num_events\"], \n",
    "                    type_=\"hdf5\",\n",
    "                    use_premade=True)\n",
    "    tr,val = dl.load_data()\n",
    "\n",
    "    kwargs[\"logger\"].info(str(kwargs))\n",
    "    networks, fns = build_network(kwargs, build_layers(kwargs))\n",
    "    tv = TrainVal(tr,val, kwargs, fns, networks)\n",
    "    for epoch in range(kwargs[\"num_epochs\"]):\n",
    "        tv.do_one_epoch()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# h5_prefix = \"/project/projectdirs/dasrepo/atlas_rpv_susy/hdf5/prod003_2016_11_14\"\n",
    "\n",
    "# a=h5py.File(join(h5_prefix,\"GG_RPV10_1400_850.h5\" ))\n",
    "\n",
    "# w=a[\"event_10\"][\"weight\"]\n",
    "\n",
    "# w.value\n",
    "\n",
    "# g.value\n",
    "\n",
    "# # x.shape\n",
    "\n",
    "# # #test\n",
    "# # x, y, xv,yv = load_train_val(num_events=100000)\n",
    "\n",
    "# # def test_network(network_path):\n",
    "# #     x_te, y_te = load_test()\n",
    "\n",
    "# #     net = pickle.load(open(network_path))\n",
    "\n",
    "# #     cfg = build_network(network_kwargs,net)\n",
    "# #     return cfg['val_fn'](x_te, y_te)\n",
    "\n",
    "# # network_path = './results/run84/model.pkl'\n",
    "\n",
    "\n",
    "\n",
    "# # net = pickle.load(open(network_path))\n",
    "\n",
    "# # cfg = build_network(network_kwargs,net)\n",
    "\n",
    "# # y_pred = cfg['out_fn'](xv)\n",
    "\n",
    "# # y_pred = y_pred[0]\n",
    "\n",
    "# # best_sig = xv[np.argmax(y_pred[:,1])]\n",
    "\n",
    "# # best_bg = xv[np.argmin(y_pred[:,1])]\n",
    "\n",
    "# # plot_example(np.squeeze(best_sig))\n",
    "\n",
    "# # plot_example(np.squeeze(best_bg))\n",
    "\n",
    "# # inds = np.argsort(y_pred[:,1], axis=0)\n",
    "\n",
    "# # best_bgs = np.squeeze(xv[inds[:25]])\n",
    "\n",
    "# # best_sigs = np.squeeze(xv[inds[-26:-1]])\n",
    "\n",
    "# # plot_examples(best_bgs,5, run_dir,\"best_bg\")\n",
    "\n",
    "# # plot_examples(best_sigs,5, run_dir, \"best_sig\")\n",
    "\n",
    "# # plot_filters(net,save_dir=run_dir)\n",
    "\n",
    "# # plot_feature_maps(best_bgs[0], net, run_dir, name=\"best_bg\")\n",
    "\n",
    "# # best_bg = np.expand_dims(np.expand_dims(best_bgs[0], axis=0),axis=0)\n",
    "# # best_sig = np.expand_dims(np.expand_dims(best_sigs[-1], axis=0),axis=0)\n",
    "# # saliency_fn = compile_saliency_function(net)\n",
    "# # saliency, max_class = saliency_fn(best_sig)\n",
    "# # #np.squeeze(np.abs(saliency)).shape\n",
    "# # show_images(best_sigs[-1], saliency, max_class, \"default gradient\", save_dir=run_dir)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
