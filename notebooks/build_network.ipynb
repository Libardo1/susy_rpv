{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import Conv2DLayer\n",
    "from lasagne.layers import MaxPool2DLayer\n",
    "from lasagne.layers import dropout\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.nonlinearities import rectify as relu\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import sys\n",
    "import numpy as np\n",
    "#enable importing of notebooks\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import inspect\n",
    "# from helper_fxns import get_best_box, get_detec_loss, get_iou, make_test_data, get_detec_acc, get_final_box\n",
    "# if __name__ == \"__main__\":\n",
    "#     from data_loader import load_classification_dataset, load_detection_dataset\n",
    "\n",
    "def build_network(learning_rate=0.001,\n",
    "                  weight_decay=0.00005,\n",
    "                  momentum=0.9,\n",
    "                  input_shape=(None,1,100,100), \n",
    "                  weight_load_path=None,\n",
    "                  nonlinearity=relu,\n",
    "                  num_filters=128,\n",
    "                  num_fc_units=512,\n",
    "                  w_init=lasagne.init.HeUniform(),\n",
    "                  dropout_p=0.5):\n",
    "    \n",
    "    \n",
    "    input_var = T.tensor4('input_var')\n",
    "    target_var = T.ivector('target_var')\n",
    "    \n",
    "    network = build_layers(input_var,\n",
    "                           input_shape,\n",
    "                           nonlinearity,\n",
    "                           num_filters,\n",
    "                           num_fc_units,\n",
    "                           w_init,\n",
    "                           dropout_p)\n",
    "    \n",
    "    \n",
    "    # gets frame which has function keys, values in order to save hyper params\n",
    "    hyperparams = get_hyperparams(inspect.currentframe())\n",
    "    \n",
    "    #if we are loading pretrained weights\n",
    "    if weight_load_path:\n",
    "        network = load_weights(weight_load_path, network)\n",
    "        \n",
    "    '''write loss function equation'''\n",
    "    prediction = lasagne.layers.get_output(network, deterministic=False)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    weightsl2 = lasagne.regularization.regularize_network_params(network, lasagne.regularization.l2)\n",
    "    loss += weight_decay * weightsl2\n",
    "    \n",
    "    \n",
    "    '''calculate test loss (cross entropy with no regularization) and accuracy'''\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    \n",
    "    '''classification percentage: we can change this based on false postive/false negative criteria'''\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var))\n",
    "\n",
    "    '''calculate updates -> nesterov momentum sgd'''\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    \n",
    "    #new_weight += momentum*prev_step  - leaarning_rate * (dL(cur_weight + momentum*prev_step)/dcur_weight) \n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''train_fn -> takes in input,label pairs -> outputs loss '''\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "\n",
    "    '''val_fn -> takes in input,label pairs -> outputs non regularized loss and accuracy '''\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "\n",
    "    return train_fn, val_fn, network, hyperparams\n",
    "\n",
    "def build_layers(input_var,\n",
    "                 input_shape,\n",
    "                 nonlinearity,\n",
    "                 num_filters,\n",
    "                 num_fc_units,\n",
    "                 w_init,\n",
    "                 dropout_p):\n",
    "    \n",
    "    \n",
    "\n",
    "    conv_kwargs = dict(num_filters=num_filters, filter_size=(3,3), pad=1, nonlinearity=nonlinearity, W=w_init)\n",
    "    \n",
    "    #eqn for reference: new_im_shape = (im_shape + 2*pad - filt_size ) / stride +1\n",
    "    \n",
    "    #shape: 1,100,100\n",
    "    network = InputLayer(shape=input_shape, input_var=input_var)\n",
    "    \n",
    "    #shape: num_filters, 100,100\n",
    "    network = Conv2DLayer(network, **conv_kwargs)\n",
    "    \n",
    "    #shape: num_filters, 50, 50\n",
    "    network = MaxPool2DLayer(network, pool_size=(2,2),stride=2)\n",
    "    \n",
    "    #shape: num_filters, 50, 50\n",
    "    network = Conv2DLayer(network, **conv_kwargs)\n",
    "    \n",
    "    #shape: num_filters, 25,25\n",
    "    network = MaxPool2DLayer(network, pool_size=(2,2), stride=2)\n",
    "    \n",
    "    #shape: num_filters,24,24 (made this one different to get to an even number)\n",
    "    network = Conv2DLayer(network,num_filters=num_filters, filter_size=(4,4), pad=1, \n",
    "                          nonlinearity=nonlinearity, W=w_init )\n",
    "    \n",
    "    #shape: num_filters, 12, 12\n",
    "    network = MaxPool2DLayer(network, pool_size=(2,2), stride=2)\n",
    "    \n",
    "    #shape: num_fc_units\n",
    "    network = dropout(network, p=dropout_p)\n",
    "    network = DenseLayer(network,num_units=num_fc_units, nonlinearity=relu) \n",
    "    \n",
    "    #shape: 2 (2 classes)\n",
    "    network = dropout(network, p=dropout_p)\n",
    "    network = DenseLayer(network, num_units=2, nonlinearity=lasagne.nonlinearities.softmax) \n",
    "    \n",
    "    return network\n",
    "\n",
    "def load_weights(file_path, network):\n",
    "    '''grabs weights from an npz file'''\n",
    "    with np.load(file_path) as f:\n",
    "        param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "        lasagne.layers.set_all_param_values(network, param_values)\n",
    "    return network\n",
    "    \n",
    "\n",
    "def get_hyperparams(frame):\n",
    "    #get function key, values\n",
    "    args, _, _, values = inspect.getargvalues(frame)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_fn, val_fn, network =build_network()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
