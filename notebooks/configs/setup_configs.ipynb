{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named notebooks.load_data.data_loader",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f6b4351481e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnotebooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAnomalyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnotebooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetworks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinary_classic_convnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnotebooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetworks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_ae_anom\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named notebooks.load_data.data_loader"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import argparse\n",
    "from os.path import join\n",
    "from notebooks.load_data.data_loader import DataLoader, AnomalyLoader, DataIterator\n",
    "from notebooks.networks import binary_classifier as bc\n",
    "#from notebooks.networks import anom_ae as aa\n",
    "from notebooks.util import create_run_dir, get_logger, dump_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_args = {'input_shape': tuple([None] + [1, 64, 64]), \n",
    "                      'learning_rate': 0.00001, \n",
    "                      'dropout_p': 0.0, \n",
    "                      'weight_decay': 0.0,\n",
    "                      'num_filters': 128, \n",
    "                      'num_fc_units': 512,\n",
    "                      'num_layers': 3,\n",
    "                      'momentum': 0.9,\n",
    "                      'num_epochs': 20000,\n",
    "                      'batch_size': 1024,\n",
    "                      \"save_path\": \"None\",\n",
    "                      \"num_tr\": -1,\n",
    "                      \"test\":False, \n",
    "                        \"seed\": 7,\n",
    "                      \"mode\":\"classif\",\n",
    "                      \"ae\":False,\n",
    "                      \"exp_name\": \"run\",\n",
    "                      \"load_path\": \"None\",\n",
    "                      \"num_test\": -1,\n",
    "                      \"tr_file\":\"/home/evan/data/atlas/train.h5\",\n",
    "                      \"val_file\": \"/home/evan/data/atlas/val.h5\",\n",
    "                      \"test_file\": \"/home/evan/data/atlas/test.h5\",\n",
    "                      \"no_batch_norm\": False\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_configs():\n",
    "    \n",
    "\n",
    "    \n",
    "    # if inside a notebook, then get rid of weird notebook arguments, so that arg parsing still works\n",
    "    if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "        sys.argv=sys.argv[:1]\n",
    "\n",
    "\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    #make a command line argument for every flag in default args\n",
    "    for k,v in default_args.iteritems():\n",
    "        if type(v) is bool:\n",
    "            parser.add_argument('--' + k, action='store_true', help=k)\n",
    "        else:\n",
    "            parser.add_argument('--' + k, type=type(v), default=v, help=k)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    kwargs = default_args\n",
    "    kwargs.update(args.__dict__)\n",
    "    \n",
    "    \n",
    "    kwargs = setup_res_dir(kwargs)\n",
    "    \n",
    "    kwargs = setup_iterators(kwargs)\n",
    "\n",
    "    kwargs[\"logger\"] = get_logger(kwargs['save_path'])\n",
    "    \n",
    "    if kwargs[\"ae\"]:\n",
    "        net = aa\n",
    "    else:\n",
    "        net = bc\n",
    "        \n",
    "    kwargs[\"net\"] = net\n",
    "\n",
    "\n",
    "    #kwargs[\"num_train\"], kwargs[\"num_val\"] = trdi.hgroup[\"hist\"].shape[0], valdi.hgroup[\"hist\"].shape[0]\n",
    "    kwargs[\"logger\"].info(str(kwargs))\n",
    "    \n",
    "    dump_hyperparams(dic=kwargs,path=kwargs[\"save_path\"])\n",
    "\n",
    "\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_iterators(kwargs):\n",
    "    loader_kwargs = dict(groupname=\"all_events\",\n",
    "                         batch_size=kwargs[\"batch_size\"], \n",
    "                         keys=[\"hist\", \"weight\", \"normalized_weight\", \"y\"])\n",
    "    kwargs[\"loader_kwargs\"] = loader_kwargs\n",
    "    \n",
    "    trdi = DataIterator(kwargs[\"tr_file\"],num_events=kwargs[\"num_tr\"], **loader_kwargs)\n",
    "    kwargs[\"tr_iterator\"] = trdi\n",
    "    \n",
    "    kwargs[\"num_val\"] = kwargs[\"num_tr\"] if kwargs[\"num_tr\"] == -1 else int(0.2*kwargs[\"num_tr\"])\n",
    "    valdi = DataIterator(kwargs[\"val_file\"],num_events=kwargs[\"num_val\"],**loader_kwargs)\n",
    "    kwargs[\"val_iterator\"] = valdi\n",
    "    \n",
    "    kwargs[\"test_iterator\"] = DataIterator(kwargs[\"test_file\"],num_events=kwargs[\"num_test\"],**loader_kwargs)\n",
    "\n",
    "    kwargs[\"input_shape\"] = tuple([None,1] + list(trdi.hgroup[\"hist\"].shape[1:]))\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_res_dir(kwargs):\n",
    "    if kwargs[\"save_path\"]== \"None\":\n",
    "        kwargs[\"save_path\"] = None\n",
    "\n",
    "    run_dir = create_run_dir(kwargs[\"save_path\"], name=kwargs[\"exp_name\"])\n",
    "    kwargs['save_path'] = run_dir\n",
    "    return kwargs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
