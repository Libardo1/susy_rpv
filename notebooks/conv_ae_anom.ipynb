{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.objectives import *\n",
    "from lasagne.regularization import regularize_network_params, l2\n",
    "from lasagne.updates import *\n",
    "from lasagne.init import *\n",
    "from lasagne.nonlinearities import rectify as relu\n",
    "from lasagne.nonlinearities import *\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import sys\n",
    "import numpy as np\n",
    "#enable importing of notebooks\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import inspect\n",
    "import copy\n",
    "from theano.ifelse import ifelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from helper_fxns import get_best_box, get_detec_loss, get_iou, make_test_data, get_detec_acc, get_final_box\n",
    "# if __name__ == \"__main__\":\n",
    "#     from data_loader import load_classification_dataset, load_detection_dataset\n",
    "\n",
    "def build_network(args, network):\n",
    "    X = T.tensor4('X')\n",
    "    #Y = T.tensor4('Y')\n",
    "    thresh = 1.0\n",
    "    #network = build_layers(args)\n",
    "    '''write loss function equation'''\n",
    "    prediction = get_output(network, X)\n",
    "    loss = squared_error(prediction, X).mean()\n",
    "    weightsl2 = regularize_network_params(network, l2).sum()\n",
    "    loss += args['weight_decay'] * weightsl2\n",
    "    \n",
    "    '''calculate test loss (cross entropy with no regularization) and accuracy'''\n",
    "    test_prediction = get_output(network, X, deterministic=True)\n",
    "    test_loss = squared_error(test_prediction, X).sum()\n",
    "    \n",
    "    \n",
    "    '''classification percentage: we can change this based on false postive/false negative criteria'''\n",
    "    '''max reconstriuction error'''\n",
    "    test_acc = test_loss \n",
    "    test_score = T.sum(squared_error(test_prediction, X), axis=(1,2,3))\n",
    "    with T.autocast_float_as(\"float64\"):\n",
    "        test_score = test_score / (T.prod(X.shape[1:]))\n",
    "        inds = test_score[test_score > thresh].nonzero()\n",
    "        test_score = T.set_subtensor(test_score[inds], 1) \n",
    "        #test_score = ifelse(T.gt(test_score,thresh), thresh,test_score )\n",
    "        test_score = 1 - test_score\n",
    "    params = get_all_params(network, trainable=True)\n",
    "    \n",
    "    updates = adam(loss, learning_rate=args['learning_rate'], params=params)\n",
    "    #updates = nesterov_momentum(loss, params, learning_rate=args['learning_rate'], momentum=args['momentum'])\n",
    "    \n",
    "    \n",
    "    '''train_fn -> takes in input,label pairs -> outputs loss '''\n",
    "    train_fn = theano.function([X], loss, updates=updates)\n",
    "    \n",
    "    \n",
    "    '''val_fn -> takes in input,label pairs -> outputs non regularized loss and accuracy '''\n",
    "    val_fn = theano.function([X], test_loss)\n",
    "    acc_fn = theano.function([X], test_acc)\n",
    "    out_fn = theano.function([X], test_prediction)\n",
    "    score_fn = theano.function([X], test_score)\n",
    "    return {\"net\":network}, {'tr': train_fn, \n",
    "                            'val': val_fn,\n",
    "                            'acc': acc_fn,\n",
    "                            'out': out_fn, \n",
    "                            \"score\": score_fn}\n",
    "\n",
    "def build_layers(args):\n",
    "    \n",
    "    conv_kwargs = dict(num_filters=args['num_filters'], \n",
    "                       filter_size=4, pad=1,stride=2, nonlinearity=relu, W=HeNormal(gain=\"relu\"))\n",
    "    deconv_kwargs = copy.deepcopy(conv_kwargs)\n",
    "    deconv_kwargs[\"crop\"] = conv_kwargs[\"pad\"]\n",
    "    del deconv_kwargs[\"pad\"]\n",
    "    \n",
    "    network = InputLayer(shape=args['input_shape'])\n",
    "    for lay in range(args['num_layers']):\n",
    "        network = batch_norm(Conv2DLayer(network, **conv_kwargs))\n",
    "        #network = MaxPool2DLayer(network, pool_size=(2,2),stride=2)\n",
    "    for lay in range(args['num_layers']):\n",
    "        if lay == args['num_layers'] - 1:\n",
    "            deconv_kwargs[\"num_filters\"] = args['input_shape'][1]\n",
    "            deconv_kwargs[\"nonlinearity\"] = sigmoid\n",
    "        network = Deconv2DLayer(network,**deconv_kwargs)\n",
    "    #network = NonlinearityLayer(network,nonlinearity=tanh)\n",
    "    \n",
    "    \n",
    "    for layer in get_all_layers(network):\n",
    "        if \"logger\" in args:\n",
    "            args[\"logger\"].info(str(layer) + str(layer.output_shape))\n",
    "        else:\n",
    "            print str(layer) + str(layer.output_shape)\n",
    "    print count_params(layer)\n",
    "    \n",
    "    return network\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# def auc(pred,gt):\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lasagne.layers.input.InputLayer object at 0x2aca709f0d10>(None, 1, 64, 64)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2aca70a30410>(None, 10, 32, 32)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2aca70a4e850>(None, 10, 32, 32)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2aca70a613d0>(None, 10, 32, 32)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2aca70a61510>(None, 10, 16, 16)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2aca70a61710>(None, 10, 16, 16)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2aca70a61ad0>(None, 10, 16, 16)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2aca70a61c10>(None, 10, 8, 8)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2aca70a61e10>(None, 10, 8, 8)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2aca70a6b210>(None, 10, 8, 8)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x2aca70a6b350>(None, 10, 16, 16)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x2aca70a6b490>(None, 10, 32, 32)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x2aca70a6b710>(None, 1, 64, 64)\n",
      "6861\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The two branches should have identical types, but they are TensorType(float64, scalar) and TensorType(float64, vector) respectively. This error could be raised if for example you provided a one element list on the `then` branch but a tensor on the `else` branch.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0723dbd78a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                  \"sig_eff_at\": 0.9996, \"test\":False, \"seed\": 7}\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m  \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m  \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c59cc8eefd6e>\u001b[0m in \u001b[0;36mbuild_network\u001b[0;34m(args, network)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_float_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifelse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_score\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/cori/software/python/2.7-anaconda/envs/deeplearning/lib/python2.7/site-packages/theano/ifelse.pyc\u001b[0m in \u001b[0;36mifelse\u001b[0;34m(condition, then_branch, else_branch, name)\u001b[0m\n\u001b[1;32m    365\u001b[0m                     \u001b[0;34m'list on the `then` branch but a tensor on the `else` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                     \u001b[0;34m'branch.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                     (then_branch_elem.type, else_branch_elem.type))\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mnew_then_branch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthen_branch_elem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The two branches should have identical types, but they are TensorType(float64, scalar) and TensorType(float64, vector) respectively. This error could be raised if for example you provided a one element list on the `then` branch but a tensor on the `else` branch."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":   \n",
    "    args = {'input_shape': tuple([None] + [1, 64, 64]), \n",
    "                          'learning_rate': 0.01, \n",
    "                          'dropout_p': 0, \n",
    "                          'weight_decay': 0, #0.0001, \n",
    "                          'num_filters': 10, \n",
    "                          'num_fc_units': 32,\n",
    "                          'num_layers': 3,\n",
    "                          'momentum': 0.9,\n",
    "                          'num_epochs': 20000,\n",
    "                          'batch_size': 128,\n",
    "                         \"save_path\": \"None\",\n",
    "                        \"num_events\": 100,\n",
    "                        \"sig_eff_at\": 0.9996, \"test\":False, \"seed\": 7}\n",
    "\n",
    "    net, fns = build_network(args, build_layers(args))\n",
    "    x = np.random.random((40,1,64,64))\n",
    "    \n",
    "\n",
    "    print fns[\"score\"](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16, 32, 32)\n",
      "(None, 16, 16, 16)\n",
      "(None, 16, 8, 8)\n",
      "(None, 16, 16, 16)\n",
      "(None, 16, 32, 32)\n",
      "(None, 16, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# net = InputLayer(shape=(None,8,64,64))\n",
    "\n",
    "# for i in range(3):\n",
    "#     net = Conv2DLayer(net,num_filters=16, filter_size=4,pad=1, stride=2)\n",
    "#     print get_output_shape(net)\n",
    "# for i in range(3):\n",
    "#     net = Deconv2DLayer(net,num_filters=16,filter_size=4,crop=1,stride=2)\n",
    "#     print get_output_shape(net)\n",
    "\n",
    "# get_output_shape(net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
