{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'tkurth'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "import os\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named ROOT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9ba4afba0965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/global/homes/w/wbhimji/cori-envs/nersc-rootpy/lib/python2.7/site-packages/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mROOT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrootpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroot_numpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named ROOT"
     ]
    }
   ],
   "source": [
    "sys.path.append('/global/homes/w/wbhimji/cori-envs/nersc-rootpy/lib/python2.7/site-packages/')\n",
    "import ROOT\n",
    "import rootpy\n",
    "import root_numpy as rnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a context manager to suppress stdout and stderr.\n",
    "class suppress_stdout_stderr(object):\n",
    "    '''\n",
    "    A context manager for doing a \"deep suppression\" of stdout and stderr in \n",
    "    Python, i.e. will suppress all print, even if the print originates in a \n",
    "    compiled C/Fortran sub-function.\n",
    "       This will not suppress raised exceptions, since exceptions are printed\n",
    "    to stderr just before a script exits, and after the context manager has\n",
    "    exited (at least, I think that is why it lets exceptions through).      \n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # Open a pair of null files\n",
    "        self.null_fds =  [os.open(os.devnull,os.O_RDWR) for x in range(2)]\n",
    "        # Save the actual stdout (1) and stderr (2) file descriptors.\n",
    "        self.save_fds = (os.dup(1), os.dup(2))\n",
    "\n",
    "    def __enter__(self):\n",
    "        # Assign the null pointers to stdout and stderr.\n",
    "        os.dup2(self.null_fds[0],1)\n",
    "        os.dup2(self.null_fds[1],2)\n",
    "\n",
    "    def __exit__(self, *_):\n",
    "        # Re-assign the real stdout/stderr back to (1) and (2)\n",
    "        os.dup2(self.save_fds[0],1)\n",
    "        os.dup2(self.save_fds[1],2)\n",
    "        # Close the null files\n",
    "        os.close(self.null_fds[0])\n",
    "        os.close(self.null_fds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data_hdf5(bg_files, group_name, num_events):\n",
    "\n",
    "        bgdf = pd.read_hdf(bg_files, group_name)\n",
    "        sigdf = pd.read_hdf(sig_files, group_name)\n",
    "        num_each = num_events / 2\n",
    "        x_bg = bgdf[dataset_name][:num_each]\n",
    "        x_sig = sigdf[dataset_name][:num_each]\n",
    "        #background first\n",
    "        x_concat = np.hstack((x_bg, x_sig))\n",
    "        dim_x, dim_y = x_bg[0].shape\n",
    "        x = np.zeros((num_events ,dim_x, dim_y ))\n",
    "        for i in range(num_events):\n",
    "            x[i] = x_concat[i]\n",
    "        # add a channel size of 1 as a place holder\n",
    "        x = np.expand_dims(x,axis=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(bg_cfg_file = './config/BgFileListAug16.txt',\n",
    "                sig_cfg_file='./config/SignalFileListAug16.txt',\n",
    "                group_name='CollectionTree',\n",
    "                branches=['CaloCalTopoClustersAuxDyn.calPhi', 'CaloCalTopoClustersAuxDyn.calEta','CaloCalTopoClustersAuxDyn.calE'],\n",
    "                num_events=50000,\n",
    "                preprocess=True,\n",
    "                bin_size=0.025,\n",
    "                eta_range = [-5,5],\n",
    "                phi_range = [-3.14, 3.14],\n",
    "                dataset_name='histo',\n",
    "                type_='root'):\n",
    "\n",
    "\n",
    "    bg_files = [line.rstrip() for line in open(bg_cfg_file)]\n",
    "    sig_files = [line.rstrip() for line in open(sig_cfg_file)]\n",
    "\n",
    "    events_per_sig_file = 10000\n",
    "    \n",
    "    #we assume there are more bg per file than sig, so we bound our number of files by number of files\n",
    "    #needed for a sig event\n",
    "    if num_events is not None:\n",
    "        assert num_events % 2 == 0, \"why an odd number for num_events?!, even please\"\n",
    "        num_each = num_events / 2\n",
    "\n",
    "        #get the number of files needed\n",
    "        num_files = int(np.ceil(num_each / float(events_per_sig_file)))\n",
    "\n",
    "        #because root does not do well with one file\n",
    "        if num_files == 1:\n",
    "            num_files = 2\n",
    "    else:\n",
    "        num_each = None\n",
    "        num_files = len(sig_files)\n",
    "\n",
    "    if type_ == 'hdf':\n",
    "        raise NotImplementedError\n",
    "        #x = load_data_hdf5(bg_files, group_name, num_events)\n",
    "\n",
    "    elif type_ == 'root':\n",
    "        #so we don't have annoying stderr messages\n",
    "        with suppress_stdout_stderr():\n",
    "\n",
    "            #bgarray has n_events groups of 3 parallel numpy arrays \n",
    "            #(each numpy within a group is of equal length and each array corresponds to phi, eta and the corresponding energy)\n",
    "            bgarray = rnp.root2array(bg_files[:num_files], treename=group_name, \\\n",
    "                                     branches=branches, \\\n",
    "                                     start=0, \\\n",
    "                                     stop=num_each,warn_missing_tree=True)\n",
    "\n",
    "\n",
    "\n",
    "            sigarray = rnp.root2array(sig_files[:num_files],\\\n",
    "                                      treename=group_name,\\\n",
    "                                      branches=branches,\\\n",
    "                                      start=0, \\\n",
    "                                      stop=num_each,warn_missing_tree=True)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "        bgdf = pd.DataFrame.from_records(bgarray)\n",
    "\n",
    "        sigdf = pd.DataFrame.from_records(sigarray)\n",
    "        \n",
    "        phi_bins = int(np.floor((phi_range[1] - phi_range[0]) / bin_size))\n",
    "        eta_bins = int(np.floor((eta_range[1] - eta_range[0]) / bin_size))\n",
    "\n",
    "\n",
    "        x_bg = np.zeros((num_each, 1, phi_bins, eta_bins ))\n",
    "        x_sig = np.zeros((num_each, 1, phi_bins, eta_bins ))\n",
    "\n",
    "        #num events is now num each\n",
    "        \n",
    "    \n",
    "        for i in range(num_each):\n",
    "            phi, eta, E =  bgdf['CaloCalTopoClustersAuxDyn.calPhi'][i],\\\n",
    "                           bgdf['CaloCalTopoClustersAuxDyn.calEta'][i],\\\n",
    "                           bgdf['CaloCalTopoClustersAuxDyn.calE'][i]\n",
    "\n",
    "            x_bg[i] = np.histogram2d(phi,eta, bins=(phi_bins, eta_bins), weights=E, range=[phi_range,eta_range])[0]\n",
    "\n",
    "            phi, eta, E =  sigdf['CaloCalTopoClustersAuxDyn.calPhi'][i],\\\n",
    "                           sigdf['CaloCalTopoClustersAuxDyn.calEta'][i],\\\n",
    "                           sigdf['CaloCalTopoClustersAuxDyn.calE'][i]\n",
    "            x_sig[i] = np.histogram2d(phi,eta, bins=(phi_bins, eta_bins), weights=E, range=[phi_range,eta_range])[0]\n",
    "\n",
    "\n",
    "        #background first\n",
    "        x = np.vstack((x_bg, x_sig))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # 1 means signal, 0 means background\n",
    "    y = np.zeros((num_events,)).astype('int32')\n",
    "    #make the last half signal label\n",
    "    y[num_each:] = 1\n",
    "\n",
    "\n",
    "    #shuffle examples\n",
    "    rng = np.random.RandomState(seed=9)\n",
    "\n",
    "    inds = np.arange(num_events)\n",
    "\n",
    "    rng.shuffle(inds)\n",
    "\n",
    "    return x[inds], y[inds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    data = load_data(type_='root', num_events=1000, preprocess=False, bin_size=0.2,    bg_cfg_file = '../config/BgFileListAug16.txt',\n",
    "    sig_cfg_file='../config/SignalFileListAug16.txt')\n",
    "    x,y = data\n",
    "    plt.imshow(np.log10(x[11][0]).T,extent=[-3.15, 3.15, -5, 5], interpolation='none',aspect='auto', origin='low')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "deeplearning (edison)",
   "language": "python",
   "name": "deeplearning_edison"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
