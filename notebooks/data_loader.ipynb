{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from helper_fxns.ipynb\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'racah'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "import os\n",
    "from os.path import join, exists\n",
    "from os import makedirs, mkdir\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "%matplotlib inline\n",
    "import time\n",
    "import h5py\n",
    "from helper_fxns import suppress_stdout_stderr\n",
    "import copy\n",
    "#sys.path.append('/global/homes/w/wbhimji/cori-envs/nersc-rootpy/lib/python2.7/site-packages/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffle(kwargs):\n",
    "    inds = np.arange(kwargs[kwargs.keys()[0]].shape[0])\n",
    "\n",
    "    #shuffle data\n",
    "    rng = np.random.RandomState(7)\n",
    "    rng.shuffle(inds)\n",
    "    return {k:v[inds] for k,v in kwargs.iteritems()}\n",
    "\n",
    "def split_train_val_test(prop, kwargs):\n",
    "    tr_prop = 1 - prop\n",
    "    inds = np.arange(kwargs[kwargs.keys()[0]].shape[0])\n",
    "    #split train, val, test\n",
    "    tr_inds = inds[:int((tr_prop*len(inds)))]\n",
    "    te_inds = inds[int(tr_prop*len(inds)):]\n",
    "    \n",
    "    val_inds = inds[int(tr_prop*len(inds)):]\n",
    "\n",
    "    tr = {k:v[tr_inds] for k,v in kwargs.iteritems()}\n",
    "    val = {k:v[val_inds] for k,v in kwargs.iteritems()}\n",
    "    return tr,val\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(x, max_abs=None):\n",
    "    '''a type of sparse preprocessing, which scales everything between -1 and 1 without losing sparsity'''\n",
    "    #only calculate the statistic using training set\n",
    "    if max_abs is None:\n",
    "        max_abs=np.abs(x).max(axis=(0,1,2,3))\n",
    "\n",
    "    #then scale all sets\n",
    "    x /= max_abs\n",
    "    #print np.max(x)\n",
    "    #print np.min(x)\n",
    "    return x, max_abs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self, bg_cfg_file = './config/BgFileListAug16.txt',\n",
    "                sig_cfg_file='./config/SignalFileListAug16.txt',\n",
    "                type_ = \"hdf5\",\n",
    "                num_events=50000,\n",
    "                preprocess=True,\n",
    "                bin_size=0.025,\n",
    "                eta_range = [-5,5],\n",
    "                phi_range = [-3.14, 3.14], tr_prop=0.8, use_premade=False, test=False, seed=3):\n",
    "        \n",
    "        \n",
    "        self.test = test\n",
    "        self.bg_files = bg_cfg_file if isinstance(bg_cfg_file, list) else [bg_cfg_file]\n",
    "        self.sig_files = sig_cfg_file if isinstance(sig_cfg_file, list) else [sig_cfg_file]\n",
    "        \n",
    "        tim = time.time()\n",
    "        self.bg_dict, self.sig_dict, self.fil_dict = self.get_file_metadata()\n",
    "        print \"time: \", time.time() - tim\n",
    "        self.val_prop = val_prop\n",
    "        self.phi_bins = int(np.floor((phi_range[1] - phi_range[0]) / bin_size))\n",
    "        self.eta_bins = int(np.floor((eta_range[1] - eta_range[0]) / bin_size))\n",
    "        self.eta_range = eta_range\n",
    "        self.phi_range = phi_range\n",
    "        self.seed = seed\n",
    "        self.num_events = num_events\n",
    "        \n",
    "        \n",
    "        if num_events == -1:\n",
    "            if type_ == \"hdf5\":\n",
    "                self.num_each = self.get_max_h5_events()\n",
    "        else:\n",
    "            #we assume there are more bg per file than sig, so we bound our number of files by number of files\n",
    "            #needed for a sig event\n",
    "            assert num_events % 2 == 0, \"why an odd number for num_events?!, even please\"\n",
    "            self.num_each = num_events / 2\n",
    "            \n",
    "        self.use_premade = use_premade\n",
    "        self.type_ = type_\n",
    "        \n",
    "        if type_ == \"xaod\" or type_ == \"delphes\":\n",
    "            assert False, \"Deprecated for now. Wahid will fix!\"\n",
    "            self.file_type = \"root\"\n",
    "            import ROOT\n",
    "            import rootpy\n",
    "            import root_numpy as rnp\n",
    "            self.set_root_cfgs()\n",
    "        else:\n",
    "            self.file_type = \"hdf5\"\n",
    "            self.set_h5_cfgs()\n",
    "        \n",
    "\n",
    "    \n",
    "    def get_file_metadata(self):\n",
    "        \n",
    "        bg_dict = {fil:len(h5py.File(fil).keys()) for fil in self.bg_files}\n",
    "        sig_dict = {fil:len(h5py.File(fil).keys()) for fil in self.sig_files}\n",
    "        fil_dict = copy.deepcopy(bg_dict)\n",
    "        fil_dict.update(sig_dict)\n",
    "        return bg_dict, sig_dict, fil_dict\n",
    "    def get_max_h5_events(self):\n",
    "        num_bg_events = sum([v for v in self.bg_dict.values() ])\n",
    "        num_sig_events = sum([v for v in self.sig_dict.values() ])\n",
    "        max_events = min(num_sig_events, num_bg_events)\n",
    "        return max_events\n",
    "    def set_h5_cfgs(self):\n",
    "        self.group_prefix = \"event_\"\n",
    "        self.h5keys = ['clusE',\n",
    "                       'clusEta',\n",
    "                       'clusPhi']\n",
    "         \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def set_root_cfgs(self):\n",
    "        self.events_per_sig_file = 10000\n",
    "        self.bg_files = [line.rstrip() for line in open(self.bg_cfg_files)]\n",
    "        self.sig_files = [line.rstrip() for line in open(self.sig_cfg_files)]\n",
    "        if self.num_events == -1:\n",
    "            num_files = len(self.sig_files)\n",
    "        else:\n",
    "            #get the number of files needed\n",
    "            num_files = int(np.ceil(self.num_each / float(self.events_per_sig_file)))\n",
    "\n",
    "        #because root does not do well with one file\n",
    "        self.num_files = num_files if num_files > 1 else 2\n",
    "        \n",
    "        \n",
    "\n",
    "        if self.type_ == \"delphes\":\n",
    "            self.branchMap = {\n",
    "               'Tower.Eta' : 'ClusEta',\n",
    "               'Tower.Phi' : 'ClusPhi',\n",
    "               'Tower.E' : 'ClusE',\n",
    "               'FatJet.PT' : 'FatJetPt',\n",
    "               'FatJet.Eta' : 'FatJetEta',\n",
    "               'FatJet.Phi' : 'FatJetPhi',\n",
    "               'FatJet.Mass' : 'FatJetM',\n",
    "            }\n",
    "\n",
    "            self.treename = 'Delphes'\n",
    "        elif self.type_ == \"xaod\":\n",
    "            \n",
    "\n",
    "\n",
    "            self.branch_map = {\n",
    "                            'CaloCalTopoClustersAuxDyn.calEta' : 'ClusEta',\n",
    "                            'CaloCalTopoClustersAuxDyn.calPhi' : 'ClusPhi',\n",
    "                            'CaloCalTopoClustersAuxDyn.calE' : 'ClusE',\n",
    "                            'AntiKt10LCTopoTrimmedPtFrac5SmallR20JetsAux.pt' : 'FatJetPt',\n",
    "                            'AntiKt10LCTopoTrimmedPtFrac5SmallR20JetsAux.eta' : 'FatJetEta',\n",
    "                            'AntiKt10LCTopoTrimmedPtFrac5SmallR20JetsAux.phi' : 'FatJetPhi',\n",
    "                            'AntiKt10LCTopoTrimmedPtFrac5SmallR20JetsAux.m' : 'FatJetM',\n",
    "                        }\n",
    "\n",
    "            self.treename='CollectionTree'\n",
    "    \n",
    "\n",
    "    def grab_events(self, file_list, num_files_or_events, start=0):\n",
    "        if self.file_type == \"root\":\n",
    "            x = self._grab_root_events(file_list, num_files_or_events,start)\n",
    "        else:\n",
    "            X=[]\n",
    "            W=[]\n",
    "            PSR = []\n",
    "            for file_ in file_list:\n",
    "                num_events = num_files_or_events / len(file_list)\n",
    "                if self.test:\n",
    "                    start = len(h5py.File(file_).keys()) - num_events\n",
    "                x, w, psr = self._grab_hdf5_events(file_, num_events , start)\n",
    "                X.append(x)\n",
    "                W.append(w)\n",
    "                PSR.append(psr)\n",
    "            x = np.vstack(tuple(X))\n",
    "            w = np.vstack(tuple(W))\n",
    "            psr = np.vstack(tuple(PSR))\n",
    "        return dict(x=x, w=w, psr=psr)\n",
    "            \n",
    "    \n",
    "    def _grab_hdf5_events(self,file_, num_events, start):\n",
    "        h5f = h5py.File(file_)\n",
    "        \n",
    "        if self.use_premade:\n",
    "            x = np.zeros((num_events, 1, 50,50 ))\n",
    "        else:\n",
    "            x = np.zeros((num_events, 1, self.phi_bins, self.eta_bins ))\n",
    "        w = np.zeros((num_events,1))\n",
    "        psr = np.zeros((num_events,1))\n",
    "        \n",
    "        #shuffle inds\n",
    "        inds = np.arange(self.fil_dict[file_])\n",
    "        np.random.RandomState(self.seed).shuffle(inds)\n",
    "        for cnt, i in enumerate(inds[start:start + num_events]):\n",
    "            event = h5f[self.group_prefix + str(i)]\n",
    "            if self.use_premade:\n",
    "                x[cnt][0] = event[\"hist\"][:]\n",
    "            else:\n",
    "                #print event.keys()\n",
    "                d = {k.lower():event[k] for k in self.h5keys }\n",
    "                x[cnt][0] = self.make_hist(d)\n",
    "            w[cnt] = event[\"weight\"].value\n",
    "            psr[cnt] = event[\"passSR\"].value\n",
    "        return x, w, psr\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _grab_root_events(self,file_list, num_files, start=0):\n",
    "        #so we don't have annoying stderr messages\n",
    "        with suppress_stdout_stderr():\n",
    "\n",
    "            #bgarray has n_events groups of 3 parallel numpy arrays \n",
    "            #(each numpy within a group is of equal length and each array corresponds to phi, eta and the corresponding energy)\n",
    "            array = rnp.root2array(file_list[:num_files],\n",
    "                                     treename=self.treename,\n",
    "                                     branches=self.branch_map.keys(),\n",
    "                                     start=start,\n",
    "                                     stop=self.num_each,\n",
    "                                     warn_missing_tree=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        x = np.zeros((self.num_each, 1, self.phi_bins, self.eta_bins ))\n",
    "\n",
    "        for i in range(self.num_each):\n",
    "            d = {v.lower() : array[k][i] for k,v in branch_map.iteritems()}\n",
    "            x[i][0] = self.make_hist(d) \n",
    "            \n",
    "        return x\n",
    "            \n",
    "    def make_hist(self, d):\n",
    "        \n",
    "        return np.histogram2d(d['clusphi'],d['cluseta'], bins=(self.phi_bins, self.eta_bins),\n",
    "                              weights=d[\"cluse\"], range=[self.phi_range,self.eta_range])[0] \n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        num = self.num_files if self.file_type == \"root\" else self.num_each\n",
    "        \n",
    "        bg = self.grab_events(self.bg_files, num)\n",
    "        sig = self.grab_events(self.sig_files, num)\n",
    "\n",
    "        #data dictionary\n",
    "        data = {k:np.vstack((bg[k],sig[k])) for k in bg.keys()}\n",
    "        \n",
    "        \n",
    "        # 1 means signal, 0 means background\n",
    "        y = np.zeros((2*self.num_each,)).astype('int32')\n",
    "        #make the last half signal label\n",
    "        y[self.num_each:] = 1\n",
    "        \n",
    "        data[\"y\"] = y\n",
    "        \n",
    "        data = shuffle(data)\n",
    "        if not self.test:\n",
    "            tr_data, val_data = split_train_val(self.val_prop, data)\n",
    "\n",
    "            tr_data[\"x\"],tm = preprocess(tr_data[\"x\"])\n",
    "            val_data[\"x\"], _ = preprocess(val_data[\"x\"],tm)\n",
    " \n",
    "            return tr_data, val_data\n",
    "        else:\n",
    "            data[\"x\"], _ = preprocess(data[\"x\"])\n",
    "            return data\n",
    "    \n",
    "    def iterate_data(self, batch_size=128):\n",
    "#         if self.num_each < batch_size / 2:\n",
    "#             batch_size = 2 * self.num_each\n",
    "#         #only support for hdf5\n",
    "#         for i in range(0, self.num_each, batch_size / 2):\n",
    "#             x_bg = self.grab_events(self.bg_files, batch_size / 2, i)\n",
    "#             x_sig = self.grab_events(self.sig_files, batch_size / 2, i)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  3.55149197578\n",
      "time:  2.96765303612\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    h5_prefix = \"/global/cscratch1/sd/racah/atlas_h5\"\n",
    "    \n",
    "    try:\n",
    "        dl = DataLoader(bg_cfg_file=[join(h5_prefix, \"jetjet_JZ4.h5\"),join(h5_prefix, \"jetjet_JZ5.h5\")],\n",
    "                    sig_cfg_file=join(h5_prefix, \"GG_RPV10_1400_850.h5\"),\n",
    "                   num_events=-1, type_=\"hdf5\",use_premade=True)\n",
    "    \n",
    "        a= dl.load_data()\n",
    "    except:\n",
    "        assert False, \"tests failed!\"\n",
    "    \n",
    "    try:\n",
    "        dl = DataLoader(bg_cfg_file=[join(h5_prefix, \"jetjet_JZ4.h5\"),join(h5_prefix, \"jetjet_JZ5.h5\")],\n",
    "                        sig_cfg_file=join(h5_prefix, \"GG_RPV10_1400_850.h5\"),\n",
    "                       num_events=-1, type_=\"hdf5\",use_premade=True, test=True)\n",
    "\n",
    "        b=dl.load_data()\n",
    "    except:\n",
    "        assert False, \"tests failed!\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
