{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'racah'\n",
    "import numpy as np\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "import os\n",
    "from os.path import join, exists\n",
    "from os import makedirs, mkdir\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import h5py\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(x, max_abs=None):\n",
    "    '''a type of sparse preprocessing, which scales everything between -1 and 1 without losing sparsity'''\n",
    "    #only calculate the statistic using training set\n",
    "    if max_abs is None:\n",
    "        max_abs=np.max(np.abs(x))\n",
    "\n",
    "    #then scale all sets\n",
    "    x /= max_abs\n",
    "\n",
    "    return x, max_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproc_file(fpath, max_val_dict={\"weight\": None}):\n",
    "    fgroup, h5f = get_atlas_h5group(fpath)\n",
    "    #fgroup[\"hist\"][:], x_max_abs = preprocess(fgroup[\"hist\"][:], max_val_dict[\"hist\"])\n",
    "    nw, w_max_abs = preprocess(fgroup[\"weight\"][:], max_val_dict[\"weight\"])\n",
    "    print nw\n",
    "    \n",
    "    fgroup.create_dataset(name=\"normalized_weight\", data=nw)\n",
    "    h5f.close()\n",
    "    \n",
    "    return w_max_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_all_files():\n",
    "    tr_path = \"/global/cscratch1/sd/racah/atlas_h5/train/train.h5\"\n",
    "    val_path = \"/global/cscratch1/sd/racah/atlas_h5/train/val.h5\"\n",
    "    test_path = \"/global/cscratch1/sd/racah/atlas_h5/test/test.h5\"\n",
    "    mv = {}\n",
    "    print \"tr\"\n",
    "    preproc_file(tr_path)\n",
    "#     print \"val\"\n",
    "#     preproc_file(val_path, mv)\n",
    "#     print \"test\"\n",
    "#     preproc_file(test_path, mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rename_files(dirpath):\n",
    "    for fname in os.listdir(dirpath):\n",
    "        orig_path = join(dirpath, fname)\n",
    "        suffix = fname.split(\"test_\")[-1]\n",
    "        new_fpath = join(dirpath, suffix)\n",
    "        \n",
    "        print  orig_path, \" -> \", new_fpath\n",
    "        os.rename(orig_path,new_fpath)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rename_files(\"/global/cscratch1/sd/racah/atlas_h5/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_atlas_h5group(filepath, key=\"all_events\"):\n",
    "    h5f = h5py.File(filepath)\n",
    "    fgroup = h5f[key]\n",
    "    return fgroup, h5f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_files(dirpath, new_fpath):\n",
    "    files = [join(dirpath,f) for f in os.listdir(dirpath)]\n",
    "    base = make_empty_dict_of_file(files[0])\n",
    "    for fpath in files:\n",
    "        if \"RPV\" in fpath:\n",
    "            sig=True\n",
    "        else:\n",
    "            sig=False\n",
    "        print fpath\n",
    "        fgroup, h5f = get_atlas_h5group(fpath)\n",
    "        \n",
    "        d = get_data_dict_from_h5group(fgroup, sig)\n",
    "        base = concat_two_dicts(base,d)\n",
    "    \n",
    "        h5f.close()\n",
    "    print base\n",
    "    print \"making new file...\"\n",
    "    make_new_file(base, new_fpath)\n",
    "    return base\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_empty_dict_of_file(filepath):\n",
    "    fgroup, h5f = get_atlas_h5group(filepath)\n",
    "    ed = {k : np.empty(tuple([0] + list(v.shape[1:]))) for k,v in fgroup.iteritems()}\n",
    "    ed[\"y\"] = np.empty((0,))\n",
    "    h5f.close()\n",
    "    return ed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_two_dicts(base,addition):\n",
    "    for k,v in addition.iteritems():\n",
    "        if len(v.shape) == 1:\n",
    "            base[k] = np.hstack((base[k], addition[k]))\n",
    "        else:\n",
    "            base[k] = np.vstack((base[k], addition[k]))\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_dict_from_h5group(h5group, sig=False):\n",
    "    d = {}\n",
    "    for k,v in h5group.iteritems():\n",
    "        d[k] = v[:]\n",
    "    num_events = d[d.keys()[0]].shape[0]\n",
    "    d[\"y\"] = np.zeros((num_events,)) if not sig else np.ones((num_events,))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_new_file(dic, new_fpath):\n",
    "    newf = h5py.File(new_fpath)\n",
    "    newg = newf.create_group(\"all_events\")\n",
    "    for k,v in dic.iteritems():\n",
    "        newg[k] = v\n",
    "    newf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_test_files(file_path_list, test_prop=0.2):\n",
    "    \n",
    "    def add_to_file(file_name, data_dict):\n",
    "        f = h5py.File(file_name, \"w\")\n",
    "        group = f.create_group(\"all_events\")\n",
    "        for k in data_dict:\n",
    "            group[k] = data_dict[k]\n",
    "        f.close()\n",
    "        \n",
    "    for file_path in file_path_list:\n",
    "        print file_path\n",
    "        h5f = h5py.File(file_path)\n",
    "        all_events = h5f[\"all_events\"]\n",
    "        num_events = all_events[\"hist\"].shape[0]\n",
    "        \n",
    "        num_test = int(test_prop * num_events)\n",
    "        \n",
    "        test_file_name = join(os.path.dirname(file_path),\"val_\" + os.path.basename(file_path))\n",
    "        train_file_name = join(os.path.dirname(file_path),\"train_\" + os.path.basename(file_path))\n",
    "        \n",
    "        inds = np.arange(num_events)\n",
    "        np.random.RandomState(11).shuffle(inds)\n",
    "        raw_data = {k:all_events[k][:] for k in all_events.keys()}\n",
    "        te_data = {k:raw_data[k][inds[:num_test]] for k in all_events.keys()}\n",
    "        tr_data = {k:raw_data[k][inds[num_test:]] for k in all_events.keys()}\n",
    "        add_to_file(test_file_name, te_data)\n",
    "        add_to_file(train_file_name, tr_data)\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "def run_split():\n",
    "    split_train_test_files(file_path_list=[\"/global/cscratch1/sd/racah/atlas_h5/train/train.h5\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/global/cscratch1/sd/racah/atlas_h5/jetjet_JZ3.h5', '/global/cscratch1/sd/racah/atlas_h5/jetjet_JZ4.h5', '/global/cscratch1/sd/racah/atlas_h5/jetjet_JZ5.h5', '/global/cscratch1/sd/racah/atlas_h5/jetjet_JZ6.h5', '/global/cscratch1/sd/racah/atlas_h5/jetjet_JZ7.h5', '/global/cscratch1/sd/racah/atlas_h5/jetjet_JZ8.h5', '/global/cscratch1/sd/racah/atlas_h5/jetjet_JZ9.h5', '/global/cscratch1/sd/racah/atlas_h5/jetjet_JZ10.h5', '/global/cscratch1/sd/racah/atlas_h5/jetjet_JZ11.h5', '/global/cscratch1/sd/racah/atlas_h5/GG_RPV10_1400_850.h5']\n",
      "/global/cscratch1/sd/racah/atlas_h5/train/train.h5\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
