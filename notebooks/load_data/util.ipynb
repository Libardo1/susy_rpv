{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join, exists\n",
    "from os import makedirs, mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename_files(dirpath):\n",
    "    for fname in os.listdir(dirpath):\n",
    "        orig_path = join(dirpath, fname)\n",
    "        suffix = fname.split(\"test_\")[-1]\n",
    "        new_fpath = join(dirpath, suffix)\n",
    "        \n",
    "        print  orig_path, \" -> \", new_fpath\n",
    "        os.rename(orig_path,new_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_atlas_h5group(filepath, key=\"all_events\"):\n",
    "    h5f = h5py.File(filepath)\n",
    "    fgroup = h5f[key]\n",
    "    return fgroup, h5f\n",
    "\n",
    "def make_empty_dict_of_file(filepath):\n",
    "    fgroup, h5f = get_atlas_h5group(filepath)\n",
    "    ed = {k : np.empty(tuple([0] + list(v.shape[1:]))) for k,v in fgroup.iteritems()}\n",
    "    ed[\"label\"] = np.empty((0,))\n",
    "    h5f.close()\n",
    "    return ed\n",
    "    \n",
    "\n",
    "def concat_two_dicts(base,addition):\n",
    "    for k,v in addition.iteritems():\n",
    "        if len(v.shape) == 1:\n",
    "            base[k] = np.hstack((base[k], addition[k]))\n",
    "        else:\n",
    "            base[k] = np.vstack((base[k], addition[k]))\n",
    "    return base\n",
    "\n",
    "def get_data_dict_from_h5group(h5group, sig=False):\n",
    "    d = {}\n",
    "    for k,v in h5group.iteritems():\n",
    "        d[k] = v[:]\n",
    "    num_events = d[d.keys()[0]].shape[0]\n",
    "    d[\"y\"] = np.zeros((num_events,)) if not sig else np.ones((num_events,))\n",
    "    return d\n",
    "\n",
    "def make_new_file(dic, new_fpath):\n",
    "    newf = h5py.File(new_fpath)\n",
    "    newg = newf.create_group(\"all_events\")\n",
    "    for k,v in dic.iteritems():\n",
    "        newg[k] = v\n",
    "    newf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(x, max_abs=None):\n",
    "    '''a type of sparse preprocessing, which scales everything between -1 and 1 without losing sparsity'''\n",
    "    #only calculate the statistic using training set\n",
    "    if max_abs is None:\n",
    "        max_abs=np.max(np.abs(x))\n",
    "\n",
    "    #then scale all sets\n",
    "    x /= max_abs\n",
    "\n",
    "    return x, max_abs\n",
    "\n",
    "def preproc_file(fpath, max_val_dict={\"weight\": None,\"data\": None}):\n",
    "    fgroup, h5f = get_atlas_h5group(fpath)\n",
    "    hist_normalized, x_max_abs = preprocess(fgroup[\"data\"][:], max_val_dict[\"data\"])\n",
    "    fgroup[\"data\"][:] = hist_normalized\n",
    "    nw, w_max_abs = preprocess(fgroup[\"weight\"][:], max_val_dict[\"weight\"])\n",
    "    \n",
    "    fgroup.create_dataset(name=\"normweight\", data=nw)\n",
    "    h5f.close()\n",
    "    \n",
    "    return {\"weight\": w_max_abs,\"data\": x_max_abs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
