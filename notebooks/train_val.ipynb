{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named notebooks.objectives",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f391022a9b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnotebooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjectives\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmakedirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmkdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named notebooks.objectives"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "import time\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "from matplotlib import patches\n",
    "import logging\n",
    "from objectives import *\n",
    "from os.path import join, exists\n",
    "from os import makedirs, mkdir\n",
    "#from data_loader import load_data\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    if batchsize > inputs.shape[0]:\n",
    "        batchsize=inputs.shape[0]\n",
    "    for start_idx in range(0,len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx: start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TrainVal(object):\n",
    "    def __init__(self, tr,val, kwargs, fns, networks):\n",
    "        self.tr = tr\n",
    "        self.val=val\n",
    "        self.metrics = {}\n",
    "        self.kwargs = kwargs\n",
    "        self.fns = fns\n",
    "        self.epoch = 0\n",
    "        self.start_time = 0\n",
    "        self.seed = 5\n",
    "        self.networks = networks\n",
    "        self.print_network(networks)\n",
    "\n",
    "    \n",
    "    def iterator(self,type_):\n",
    "        data = getattr(self,type_)\n",
    "        x,y, w,psr = [data[k] for k  in [\"x\",\"y\", 'w', \"psr\"]]\n",
    "        return iterate_minibatches(x,y,batchsize=self.kwargs[\"batch_size\"], shuffle=True)\n",
    "    \n",
    "    def print_network(self, networks):\n",
    "        for net in networks.values():\n",
    "            self._print_network(net)\n",
    "            \n",
    "            \n",
    "    def _print_network(self, network):\n",
    "        self.kwargs['logger'].info(\"\\n\")\n",
    "        for layer in get_all_layers(network):\n",
    "            self.kwargs['logger'].info(str(layer) +' : ' + str(layer.output_shape))\n",
    "        self.kwargs['logger'].info(str(count_params(layer)))\n",
    "        self.kwargs['logger'].info(\"\\n\")\n",
    "    \n",
    "    def do_one_epoch(self):\n",
    "        self._do_one_epoch(type_=\"tr\")\n",
    "        self._do_one_epoch(type_=\"val\")\n",
    "        if self.epoch > 2 :\n",
    "            self.plot_learn_curve()\n",
    "        self.print_results()\n",
    "        self.epoch += 1\n",
    "    \n",
    "    def _do_one_epoch(self, type_=\"tr\"):\n",
    "        print \"beginning epoch %i\" % (self.epoch)\n",
    "        start_time = time.time()\n",
    "        metrics_tots = {}\n",
    "        batches = 0\n",
    "        for x,y in self.iterator(type_):\n",
    "            loss = self.fns[type_](x,y)\n",
    "            \n",
    "            acc = self.fns[\"acc\"](x,y)\n",
    "            \n",
    "            \n",
    "\n",
    "            loss_acc_dict = dict(loss=loss, acc=acc)\n",
    "\n",
    "            \n",
    "            for k in loss_acc_dict.keys():\n",
    "                \n",
    "                if k not in metrics_tots:\n",
    "                    metrics_tots[k] = 0\n",
    "                metrics_tots[k] += loss_acc_dict[k]\n",
    "            \n",
    "   \n",
    "            batches += 1\n",
    "        data = getattr(self, type_)\n",
    "        pred = self.fns[\"out\"](data[\"x\"])\n",
    "        #signal confidence\n",
    "        pred = pred[:,1]\n",
    "        y = data[\"y\"]\n",
    "        w = data[\"w\"]\n",
    "        \n",
    "        metrics_tots = {k: v/batches for k,v in metrics_tots.iteritems()}\n",
    "        acc_d = {}\n",
    "        \n",
    "        for d in [ams(pred,y, w),\n",
    "                  bg_rej_sig_eff(pred,y,w),\n",
    "                  sig_eff_at(self.kwargs[\"sig_eff_at\"], pred,y,w)]:\n",
    "            for k,v in d.iteritems():\n",
    "                key = type_ + \"_\" + k\n",
    "                if key not in self.metrics:\n",
    "                    self.metrics[key] = []\n",
    "                self.metrics[key].append(v)\n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "        assert batches > 0\n",
    "        for k,v in metrics_tots.iteritems():\n",
    "            key = type_ + \"_\" + k\n",
    "            if key not in self.metrics:\n",
    "                self.metrics[key] = []\n",
    "            self.metrics[key].append(v)\n",
    "\n",
    "        time_key = type_ + \"_time\"\n",
    "        if time_key not in self.metrics:\n",
    "            self.metrics[time_key] = []\n",
    "        self.metrics[time_key].append(time.time() - start_time)\n",
    "\n",
    "        \n",
    "        self.plot_roc_curve(type_)\n",
    "        if type_ == \"val\":\n",
    "            self.save_weights()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def save_weights(self):\n",
    "        max_metrics = [\"val_acc\", \"val_ams\", \"val_sig_eff\", \"val_bg_rej\", \"val_sig_eff_at_\" + str(self.kwargs[\"sig_eff_at\"])]\n",
    "        min_metrics = [\"val_loss\"]\n",
    "        for k in max_metrics:\n",
    "            if len(self.metrics[k]) > 1:\n",
    "                if self.metrics[k][-1] > max(self.metrics[k][:-1]):\n",
    "                    self._save_weights(\"net\", \"best_\" + k)\n",
    "        \n",
    "        \n",
    "            else:\n",
    "                self._save_weights(\"net\", \"best_\" + k)\n",
    "        for k in min_metrics:\n",
    "            if len(self.metrics[k]) > 1:\n",
    "                if self.metrics[k][-1] < min(self.metrics[k][:-1]):\n",
    "                    self._save_weights(\"net\", \"best_\" + k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self._save_weights(\"net\", \"cur\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    def _save_weights(self,name,suffix=\"\"):\n",
    "        params = get_all_param_values(self.networks[name])\n",
    "        model_dir = join(self.kwargs['save_path'], \"models\")\n",
    "        self.makedir_if_not_there(model_dir)\n",
    "        pickle.dump(params,open(join(model_dir, name + \"_\" + suffix + \".pkl\"), \"w\"))\n",
    "        \n",
    "    def makedir_if_not_there(self, dirname):\n",
    "        if not exists(dirname):\n",
    "            try:\n",
    "                mkdir(dirname)\n",
    "            except OSError:\n",
    "                makedirs(dirname)\n",
    "        \n",
    "        \n",
    "    def print_results(self):\n",
    "        self.kwargs['logger'].info(\"Epoch {} of {} took {:.3f}s\".format(self.epoch + 1, self.kwargs['num_epochs'],\n",
    "                                                                  self.metrics[\"tr_time\"][-1]))\n",
    "        for typ in [\"tr\", \"val\"]:\n",
    "            if typ == \"val\":\n",
    "                self.kwargs['logger'].info(\"\\tValidation took {:.3f}s\".format(self.metrics[\"val_time\"][-1]))\n",
    "            for k,v in self.metrics.iteritems():\n",
    "                #print k,v\n",
    "                if typ in k[:4] and \"time\" not in k:\n",
    "                    if \"acc\" in k:\n",
    "                        self.kwargs['logger'].info(\"\\t\\t\" + k + \":\\t\\t{:.4f} %\".format(v[-1] * 100))\n",
    "                    else:\n",
    "                        \n",
    "                        \n",
    "                        self.kwargs['logger'].info(\"\\t\\t\" + k + \":\\t\\t{:.4f}\".format(v[-1]))\n",
    "        \n",
    "    \n",
    "    def plot_roc_curve(self, type_):\n",
    "        data = getattr(self, type_)\n",
    "        pred = self.fns[\"out\"](data[\"x\"])\n",
    "        #signal preds\n",
    "        pred = pred[:,1]\n",
    "        roc = roc_vals(pred, data[\"y\"], data[\"w\"])\n",
    "        roc_path = join(self.kwargs['save_path'], \"roc_curves\")\n",
    "        self.makedir_if_not_there(roc_path)\n",
    "        plt.clf()\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        plt.title('%s ROC Curve' %(type_))\n",
    "        plt.plot(roc[\"fpr\"], roc[\"tpr\"])\n",
    "        plt.legend( loc = 'center left', bbox_to_anchor = (1.0, 0.5),\n",
    "           ncol=2)\n",
    "        plt.savefig(\"%s/%s_roc_curve.png\"%(roc_path,type_))\n",
    "        #plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def plot_learn_curve(self):\n",
    "        for k in self.metrics.keys():\n",
    "            if \"time\" not in k:\n",
    "                self._plot_learn_curve('_'.join(k.split(\"_\")[1:]))\n",
    "        \n",
    "    def _plot_learn_curve(self,type_):\n",
    "        plt.clf()\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        plt.title('Train/Val %s' %(type_))\n",
    "        plt.plot(self.metrics['tr_' + type_], label='train ' + type_)\n",
    "        plt.plot(self.metrics['val_' + type_], label='val ' + type_)\n",
    "        plt.legend( loc = 'center left', bbox_to_anchor = (1.0, 0.5),\n",
    "           ncol=2)\n",
    "\n",
    "        curves_path = join(self.kwargs['save_path'], \"learn_curves\")\n",
    "        self.makedir_if_not_there(curves_path)\n",
    "        plt.savefig(\"%s/%s_learning_curve.png\"%(curves_path,type_))\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    " \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_val(net_cfg, kwargs, data):\n",
    "    \n",
    "    logger = kwargs[\"logger\"]\n",
    "    x_tr, y_tr, x_val, y_val = data\n",
    "    logger.info(\"training set size: %i, val set size %i \" %( x_tr.shape[0], x_val.shape[0]))\n",
    "\n",
    "    tr_losses = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    tr_accs = []\n",
    "    for epoch in range(kwargs['num_epochs']):\n",
    "\n",
    "        start = time.time() \n",
    "        tr_loss = 0\n",
    "        tr_acc = 0\n",
    "        for iteration, (x, y) in enumerate(iterate_minibatches(x_tr,y_tr, batchsize=kwargs['batch_size'])):\n",
    "            #x = np.squeeze(x)\n",
    "            loss = net_cfg['tr_fn'](x, y)\n",
    "            weights = sum([np.sum(a.eval()) for a in get_all_params(net_cfg['network']) if str(a) == 'W'])\n",
    "            #logger.info(\"weights : %6.3f\" %(weights))\n",
    "            #logger.info(\"x avg : %5.5f shape: %s : iter: %i  loss : %6.3f \" % (np.mean(x), str(x.shape), iteration, loss))\n",
    "            _, acc = net_cfg['val_fn'](x,y)\n",
    "            logger.info(\"iteration % i train loss is %f\"% (iteration, loss))\n",
    "            logger.info(\"iteration % i train acc is %f\"% (iteration, acc))\n",
    "            tr_acc += acc\n",
    "            tr_loss += loss\n",
    "\n",
    "        train_end = time.time()\n",
    "        tr_avgacc = tr_acc / (iteration + 1)\n",
    "        tr_avgloss = tr_loss / (iteration + 1)\n",
    "\n",
    "\n",
    "        logger.info(\"train time : %5.2f seconds\" % (train_end - start))\n",
    "        logger.info(\"  epoch %i of %i train loss is %f\" % (epoch, kwargs[\"num_epochs\"], tr_avgloss))\n",
    "        logger.info(\"  epoch %i of %i train acc is %f percent\" % (epoch, kwargs[\"num_epochs\"], tr_avgacc * 100))\n",
    "        tr_losses.append(tr_avgloss)\n",
    "        tr_accs.append(tr_avgacc)\n",
    "\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        for iteration, (xval, yval) in enumerate(iterate_minibatches(x_val,y_val, batchsize=kwargs['batch_size'])):\n",
    "            #xval = np.squeeze(xval)\n",
    "            loss, acc = net_cfg['val_fn'](xval, yval)\n",
    "            val_loss += loss\n",
    "            val_acc += acc\n",
    "\n",
    "        val_avgloss = val_loss / (iteration + 1)\n",
    "        val_avgacc = val_acc / (iteration + 1)\n",
    "\n",
    "        logger.info(\"val time : %5.2f seconds\" % (time.time() - train_end))\n",
    "        logger.info(\"  epoch %i of %i val loss is %f\" % (epoch, kwargs[\"num_epochs\"], val_avgloss))\n",
    "        logger.info(\"  epoch %i of %i val acc is %f percent\" % (epoch, kwargs[\"num_epochs\"], val_avgacc * 100))\n",
    "\n",
    "        val_losses.append(val_avgloss)\n",
    "        val_accs.append(val_avgacc)\n",
    "\n",
    "        plot_learn_curve(tr_losses, val_losses, save_dir=kwargs[\"save_dir\"])\n",
    "        plot_learn_curve(tr_accs, val_accs, save_dir=kwargs[\"save_dir\"], name=\"acc\")\n",
    "        pickle.dump(net_cfg['network'],open(kwargs[\"save_dir\"] + \"/model.pkl\", 'w'))\n",
    "\n",
    "    #     if epoch % 5 == 0:\n",
    "    #         plot_filters(net_cfg['network'], save_dir=run_dir)\n",
    "    #         for iteration, (xval, yval) in enumerate(iterate_minibatches(x_val,y_val, batchsize=batchsize)):\n",
    "    #             plot_feature_maps(iteration, xval,net_cfg['network'], save_dir=run_dir)\n",
    "    #             break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "deeplearning_plus_root",
   "language": "python",
   "name": "deeplearning_plus_root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
