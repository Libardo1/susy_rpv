{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named notebooks.objectives",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f391022a9b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnotebooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjectives\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmakedirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmkdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named notebooks.objectives"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "import time\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "from matplotlib import patches\n",
    "import logging\n",
    "from objectives import *\n",
    "from os.path import join, exists\n",
    "from os import makedirs, mkdir\n",
    "#from data_loader import load_data\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    if batchsize > inputs.shape[0]:\n",
    "        batchsize=inputs.shape[0]\n",
    "    for start_idx in range(0,len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx: start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TrainVal(object):\n",
    "    def __init__(self, data, kwargs, fns, networks):\n",
    "        self.data=data\n",
    "        self.metrics = {}\n",
    "        self.kwargs = kwargs\n",
    "        self.fns = fns\n",
    "        self.epoch = 0\n",
    "        self.start_time = 0\n",
    "        self.seed = 5\n",
    "        self.networks = networks\n",
    "        self.print_network(networks)\n",
    "\n",
    "    \n",
    "    def iterator(self,type_):\n",
    "        data = self.data[type_]\n",
    "        x,y, w,psr = [data[k] for k  in [\"x\",\"y\", 'w', \"psr\"]]\n",
    "        return iterate_minibatches(x,y,batchsize=self.kwargs[\"batch_size\"], shuffle=True)\n",
    "    \n",
    "    def print_network(self, networks):\n",
    "        for net in networks.values():\n",
    "            self._print_network(net)\n",
    "            \n",
    "            \n",
    "    def _print_network(self, network):\n",
    "        self.kwargs['logger'].info(\"\\n\")\n",
    "        for layer in get_all_layers(network):\n",
    "            self.kwargs['logger'].info(str(layer) +' : ' + str(layer.output_shape))\n",
    "        self.kwargs['logger'].info(str(count_params(layer)))\n",
    "        self.kwargs['logger'].info(\"\\n\")\n",
    "    \n",
    "    def train_one_epoch(self):\n",
    "        self._do_one_epoch(type_=\"tr\")\n",
    "        self._do_one_epoch(type_=\"val\")\n",
    "        self.plot_learn_curve()\n",
    "        self.print_results()\n",
    "        self.epoch += 1\n",
    "    \n",
    "    def train(self):\n",
    "        for epoch in range(self.kwargs[\"num_epochs\"]):\n",
    "            tv.train_one_epoch()\n",
    "            \n",
    "    def test(self):\n",
    "        self._do_one_epoch(type_=\"test\")\n",
    "        self.print_results()\n",
    "        \n",
    "    def _do_one_epoch(self, type_=\"tr\"):\n",
    "        print \"beginning epoch %i\" % (self.epoch)\n",
    "        start_time = time.time()\n",
    "        metrics_tots = {}\n",
    "        batches = 0\n",
    "        for x,y in self.iterator(type_):\n",
    "            loss = self.fns[type_](x,y)\n",
    "            \n",
    "            acc = self.fns[\"acc\"](x,y)\n",
    "            \n",
    "            \n",
    "\n",
    "            loss_acc_dict = dict(loss=loss, acc=acc)\n",
    "\n",
    "            \n",
    "            for k in loss_acc_dict.keys():\n",
    "                \n",
    "                if k not in metrics_tots:\n",
    "                    metrics_tots[k] = 0\n",
    "                metrics_tots[k] += loss_acc_dict[k]\n",
    "            \n",
    "   \n",
    "            batches += 1\n",
    "        data = self.data[type_]\n",
    "        pred = self.fns[\"out\"](data[\"x\"])\n",
    "        #signal confidence\n",
    "        pred = pred[:,1]\n",
    "        y = data[\"y\"]\n",
    "        w = data[\"w\"]\n",
    "        cuts = data[\"psr\"]\n",
    "        \n",
    "        metrics_tots = {k: v/batches for k,v in metrics_tots.iteritems()}\n",
    "        acc_d = {}\n",
    "        \n",
    "        for d in [ams(pred,y, w),\n",
    "                  bg_rej_sig_eff(pred,y,w),\n",
    "                  sig_eff_at(self.kwargs[\"sig_eff_at\"], pred,y,w)]:\n",
    "            for k,v in d.iteritems():\n",
    "                key = type_ + \"_\" + k\n",
    "                if key not in self.metrics:\n",
    "                    self.metrics[key] = []\n",
    "                self.metrics[key].append(v)\n",
    "                \n",
    "        for d in [ams(cuts,y, w),\n",
    "                      bg_rej_sig_eff(cuts,y,w)]:\n",
    "            for k,v in d.iteritems():\n",
    "                key = type_ + \"_phys_cuts_\" + k\n",
    "                if key not in self.metrics:\n",
    "                    self.metrics[key] = []\n",
    "                self.metrics[key].append(v)\n",
    "\n",
    "            \n",
    "\n",
    "        assert batches > 0\n",
    "        for k,v in metrics_tots.iteritems():\n",
    "            key = type_ + \"_\" + k\n",
    "            if key not in self.metrics:\n",
    "                self.metrics[key] = []\n",
    "            self.metrics[key].append(v)\n",
    "\n",
    "        time_key = type_ + \"_time\"\n",
    "        if time_key not in self.metrics:\n",
    "            self.metrics[time_key] = []\n",
    "        self.metrics[time_key].append(time.time() - start_time)\n",
    "\n",
    "        \n",
    "        self.plot_roc_curve(type_)\n",
    "        if type_ == \"val\":\n",
    "            self.save_weights()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def save_weights(self):\n",
    "        max_metrics = [\"val_acc\", \"val_ams\", \"val_sig_eff\", \"val_bg_rej\", \"val_sig_eff_at_\" + str(self.kwargs[\"sig_eff_at\"])]\n",
    "        min_metrics = [\"val_loss\"]\n",
    "        for k in max_metrics:\n",
    "            if len(self.metrics[k]) > 1:\n",
    "                if self.metrics[k][-1] > max(self.metrics[k][:-1]):\n",
    "                    self._save_weights(\"net\", \"best_\" + k)\n",
    "        \n",
    "        \n",
    "            else:\n",
    "                self._save_weights(\"net\", \"best_\" + k)\n",
    "        for k in min_metrics:\n",
    "            if len(self.metrics[k]) > 1:\n",
    "                if self.metrics[k][-1] < min(self.metrics[k][:-1]):\n",
    "                    self._save_weights(\"net\", \"best_\" + k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self._save_weights(\"net\", \"cur\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    def _save_weights(self,name,suffix=\"\"):\n",
    "        params = get_all_param_values(self.networks[name])\n",
    "        model_dir = join(self.kwargs['save_path'], \"models\")\n",
    "        self.makedir_if_not_there(model_dir)\n",
    "        pickle.dump(params,open(join(model_dir, name + \"_\" + suffix + \".pkl\"), \"w\"))\n",
    "        \n",
    "    def makedir_if_not_there(self, dirname):\n",
    "        if not exists(dirname):\n",
    "            try:\n",
    "                mkdir(dirname)\n",
    "            except OSError:\n",
    "                makedirs(dirname)\n",
    "        \n",
    "     \n",
    "    \n",
    "    def print_results(self):\n",
    "        self.kwargs['logger'].info(\"Epoch {} of {} took {:.3f}s\".format(self.epoch + 1, self.kwargs['num_epochs'],\n",
    "                                                                  self.metrics[\"tr_time\"][-1]))\n",
    "        for typ in [\"tr\", \"val\"]:\n",
    "            if typ == \"val\":\n",
    "                self.kwargs['logger'].info(\"\\tValidation took {:.3f}s\".format(self.metrics[\"val_time\"][-1]))\n",
    "            for k,v in self.metrics.iteritems():\n",
    "                #print k,v\n",
    "                val = v[-1][0] if isinstance(v[-1], list) or isinstance(v[-1], np.ndarray)  else v[-1]\n",
    "                if typ in k[:4] and \"time\" not in k:\n",
    "                    if \"ams\" not in k and \"loss\" not in k:\n",
    "                        self.kwargs['logger'].info(\"\\t\\t\" + k + \":\\t\\t{:.4f} %\".format(val * 100))\n",
    "                            \n",
    "                    else:\n",
    "                        self.kwargs['logger'].info(\"\\t\\t\" + k + \":\\t\\t{:.4f}\".format(val))\n",
    "        \n",
    "    \n",
    "    def plot_roc_curve(self, type_):\n",
    "        data = getattr(self, type_)\n",
    "        pred = self.fns[\"out\"](data[\"x\"])\n",
    "        #signal preds\n",
    "        pred = pred[:,1]\n",
    "        roc = roc_vals(pred, data[\"y\"], data[\"w\"])\n",
    "        roc_path = join(self.kwargs['save_path'], \"roc_curves\")\n",
    "        self.makedir_if_not_there(roc_path)\n",
    "        plt.clf()\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        plt.title('%s ROC Curve' %(type_))\n",
    "        plt.plot(roc[\"fpr\"], roc[\"tpr\"])\n",
    "        plt.legend( loc = 'center left', bbox_to_anchor = (1.0, 0.5),\n",
    "           ncol=2)\n",
    "        plt.savefig(\"%s/%s_roc_curve.png\"%(roc_path,type_))\n",
    "        #plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def plot_learn_curve(self):\n",
    "        for k in self.metrics.keys():\n",
    "            if \"time\" not in k and \"phys\" not in k:\n",
    "                self._plot_learn_curve('_'.join(k.split(\"_\")[1:]))\n",
    "        \n",
    "    def _plot_learn_curve(self,type_):\n",
    "        plt.clf()\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        plt.title('Train/Val %s' %(type_))\n",
    "        plt.plot(self.metrics['tr_' + type_], label='train ' + type_)\n",
    "        plt.plot(self.metrics['val_' + type_], label='val ' + type_)\n",
    "        plt.legend( loc = 'center left', bbox_to_anchor = (1.0, 0.5),\n",
    "           ncol=2)\n",
    "\n",
    "        curves_path = join(self.kwargs['save_path'], \"learn_curves\")\n",
    "        self.makedir_if_not_there(curves_path)\n",
    "        plt.savefig(\"%s/%s_learning_curve.png\"%(curves_path,type_))\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    " \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "deeplearning_plus_root",
   "language": "python",
   "name": "deeplearning_plus_root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
